{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Datetime(DATE):\n",
    "    DATE['Date'] = pd.to_datetime(DATE['Timestamp'], unit='s')\n",
    "    DATE['Date']=DATE.Date.dt.strftime('%Y-%m-%d %H:%M:%S') \n",
    "    return DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Data\\part2_100000_200000.csv')\n",
    "df['Date'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "df['Date']=df.Date.dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "f=open('important_features.json')\n",
    "feature = json.load(f) \n",
    "important=feature[:10]\n",
    "important.append('Date')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mittlere_Absolute_Abweichung_y</th>\n",
       "      <th>Effektivwert_y</th>\n",
       "      <th>Standardabweichung_x</th>\n",
       "      <th>Mittelwert_x</th>\n",
       "      <th>Variance_x</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168.181</td>\n",
       "      <td>430.811</td>\n",
       "      <td>336.610</td>\n",
       "      <td>-253.696</td>\n",
       "      <td>113420.0</td>\n",
       "      <td>2021-02-12 14:26:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162.307</td>\n",
       "      <td>407.917</td>\n",
       "      <td>342.401</td>\n",
       "      <td>-253.696</td>\n",
       "      <td>117356.0</td>\n",
       "      <td>2021-02-12 14:26:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163.119</td>\n",
       "      <td>419.403</td>\n",
       "      <td>328.824</td>\n",
       "      <td>-259.072</td>\n",
       "      <td>108233.0</td>\n",
       "      <td>2021-02-12 14:26:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.958</td>\n",
       "      <td>388.749</td>\n",
       "      <td>331.830</td>\n",
       "      <td>-263.424</td>\n",
       "      <td>110221.0</td>\n",
       "      <td>2021-02-12 14:26:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157.922</td>\n",
       "      <td>413.105</td>\n",
       "      <td>319.947</td>\n",
       "      <td>-257.024</td>\n",
       "      <td>102469.0</td>\n",
       "      <td>2021-02-12 14:26:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>148.951</td>\n",
       "      <td>374.321</td>\n",
       "      <td>307.483</td>\n",
       "      <td>-176.128</td>\n",
       "      <td>94640.5</td>\n",
       "      <td>2021-05-26 00:46:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>156.334</td>\n",
       "      <td>380.399</td>\n",
       "      <td>318.900</td>\n",
       "      <td>-175.360</td>\n",
       "      <td>101799.0</td>\n",
       "      <td>2021-05-26 00:46:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>142.643</td>\n",
       "      <td>363.304</td>\n",
       "      <td>317.520</td>\n",
       "      <td>-198.400</td>\n",
       "      <td>100920.0</td>\n",
       "      <td>2021-05-26 00:46:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>156.443</td>\n",
       "      <td>390.348</td>\n",
       "      <td>299.106</td>\n",
       "      <td>-159.232</td>\n",
       "      <td>89553.8</td>\n",
       "      <td>2021-05-26 00:46:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>157.991</td>\n",
       "      <td>384.171</td>\n",
       "      <td>303.830</td>\n",
       "      <td>-161.792</td>\n",
       "      <td>92404.8</td>\n",
       "      <td>2021-05-26 00:46:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mittlere_Absolute_Abweichung_y  Effektivwert_y  Standardabweichung_x  \\\n",
       "0                             168.181         430.811               336.610   \n",
       "1                             162.307         407.917               342.401   \n",
       "2                             163.119         419.403               328.824   \n",
       "3                             151.958         388.749               331.830   \n",
       "4                             157.922         413.105               319.947   \n",
       "...                               ...             ...                   ...   \n",
       "99995                         148.951         374.321               307.483   \n",
       "99996                         156.334         380.399               318.900   \n",
       "99997                         142.643         363.304               317.520   \n",
       "99998                         156.443         390.348               299.106   \n",
       "99999                         157.991         384.171               303.830   \n",
       "\n",
       "       Mittelwert_x  Variance_x                 Date  \n",
       "0          -253.696    113420.0  2021-02-12 14:26:40  \n",
       "1          -253.696    117356.0  2021-02-12 14:26:40  \n",
       "2          -259.072    108233.0  2021-02-12 14:26:40  \n",
       "3          -263.424    110221.0  2021-02-12 14:26:40  \n",
       "4          -257.024    102469.0  2021-02-12 14:26:40  \n",
       "...             ...         ...                  ...  \n",
       "99995      -176.128     94640.5  2021-05-26 00:46:40  \n",
       "99996      -175.360    101799.0  2021-05-26 00:46:40  \n",
       "99997      -198.400    100920.0  2021-05-26 00:46:40  \n",
       "99998      -159.232     89553.8  2021-05-26 00:46:40  \n",
       "99999      -161.792     92404.8  2021-05-26 00:46:40  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[important[5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2021-02-12 14:26:40', '2021-05-25 10:53:20',\n",
       "       '2021-05-25 13:40:00', '2021-05-25 16:26:40',\n",
       "       '2021-05-25 19:13:20', '2021-05-25 22:00:00',\n",
       "       '2021-05-26 00:46:40'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart1.csv',\n",
       " 'D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart2.csv',\n",
       " 'D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart3.csv',\n",
       " 'D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart4.csv',\n",
       " 'D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart5.csv',\n",
       " 'D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart6.csv',\n",
       " 'D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart7.csv',\n",
       " 'D:\\\\studydata\\\\Masterarbeit\\\\Data\\\\withoutR\\\\axis2_demo_tablepart8.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafolder=Path(r'D:\\studydata\\Masterarbeit\\Data\\withoutR')\n",
    "dataname=os.listdir(datafolder)\n",
    "all_datapath=[]\n",
    "for name in dataname:\n",
    "   datapath=os.path.join(datafolder,name)\n",
    "   all_datapath.append(datapath)\n",
    "all_datapath.sort(key=len)\n",
    "all_datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 系统找不到指定的文件。: 'all_axis1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_axis1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 文件路径及文件名\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(size)\n",
      "File \u001b[1;32mc:\\Users\\28968\\.conda\\envs\\Autoformer\\lib\\genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetsize\u001b[39m(filename):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_size\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。: 'all_axis1.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=pd.DataFrame()\n",
    "for path in all_datapath:\n",
    "    partdata=pd.read_csv(path)\n",
    "    all=pd.concat([all,partdata])\n",
    "all.to_csv('all_axis1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319962453\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "size = os.path.getsize('all_axis1.csv') # 文件路径及文件名\n",
    "print(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1445916"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"all_axis1.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail=all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all['Date'] = pd.to_datetime(all['Timestamp'], unit='s')\n",
    "all['Date']=all.Date.dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lia68085\\\\Thesis\\\\axis1-demo_Dataset'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# current_folder =Path(r'C:\\Users\\lia68085\\Thesis\\Autoformer\\Autoformer')\n",
    "# # 将当前文件夹设置为当前工作目录\n",
    "# os.chdir(current_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=open('important_features.json')\n",
    "feature = json.load(f) \n",
    "important=feature[:5]\n",
    "important.append('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "allnew=pd.DataFrame(all)\n",
    "last=allnew[important].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Schadensklasse</th>\n",
       "      <th>Mittelwert_x</th>\n",
       "      <th>Mittelwert_y</th>\n",
       "      <th>Mittelwert_z</th>\n",
       "      <th>Variance_x</th>\n",
       "      <th>Variance_y</th>\n",
       "      <th>Variance_z</th>\n",
       "      <th>Effektivwert_x</th>\n",
       "      <th>Effektivwert_y</th>\n",
       "      <th>...</th>\n",
       "      <th>Mittlere_Absolute_Abweichung_z</th>\n",
       "      <th>Zentrales_Moment_x</th>\n",
       "      <th>Zentrales_Moment_y</th>\n",
       "      <th>Zentrales_Moment_z</th>\n",
       "      <th>Median_x</th>\n",
       "      <th>Median_y</th>\n",
       "      <th>Median_z</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>569.600</td>\n",
       "      <td>-547.072</td>\n",
       "      <td>15889.7</td>\n",
       "      <td>108005.0</td>\n",
       "      <td>26911.8</td>\n",
       "      <td>220962</td>\n",
       "      <td>657.526</td>\n",
       "      <td>571.115</td>\n",
       "      <td>...</td>\n",
       "      <td>350.131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>545.792</td>\n",
       "      <td>-545.280</td>\n",
       "      <td>15879.7</td>\n",
       "      <td>96078.5</td>\n",
       "      <td>29592.9</td>\n",
       "      <td>235057</td>\n",
       "      <td>627.592</td>\n",
       "      <td>571.746</td>\n",
       "      <td>...</td>\n",
       "      <td>363.095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>565.248</td>\n",
       "      <td>-544.512</td>\n",
       "      <td>15885.8</td>\n",
       "      <td>105404.0</td>\n",
       "      <td>24460.9</td>\n",
       "      <td>256573</td>\n",
       "      <td>651.770</td>\n",
       "      <td>566.507</td>\n",
       "      <td>...</td>\n",
       "      <td>395.262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>566.784</td>\n",
       "      <td>-541.440</td>\n",
       "      <td>15920.1</td>\n",
       "      <td>106026.0</td>\n",
       "      <td>30555.6</td>\n",
       "      <td>241982</td>\n",
       "      <td>653.578</td>\n",
       "      <td>568.931</td>\n",
       "      <td>...</td>\n",
       "      <td>389.710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>567.040</td>\n",
       "      <td>-563.456</td>\n",
       "      <td>15917.1</td>\n",
       "      <td>115510.0</td>\n",
       "      <td>26411.1</td>\n",
       "      <td>268509</td>\n",
       "      <td>661.006</td>\n",
       "      <td>586.402</td>\n",
       "      <td>...</td>\n",
       "      <td>414.196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Schadensklasse  Mittelwert_x  Mittelwert_y  Mittelwert_z  Variance_x  \\\n",
       "0   1               2       569.600      -547.072       15889.7    108005.0   \n",
       "1   2               2       545.792      -545.280       15879.7     96078.5   \n",
       "2   3               2       565.248      -544.512       15885.8    105404.0   \n",
       "3   4               2       566.784      -541.440       15920.1    106026.0   \n",
       "4   5               2       567.040      -563.456       15917.1    115510.0   \n",
       "\n",
       "   Variance_y  Variance_z  Effektivwert_x  Effektivwert_y  ...  \\\n",
       "0     26911.8      220962         657.526         571.115  ...   \n",
       "1     29592.9      235057         627.592         571.746  ...   \n",
       "2     24460.9      256573         651.770         566.507  ...   \n",
       "3     30555.6      241982         653.578         568.931  ...   \n",
       "4     26411.1      268509         661.006         586.402  ...   \n",
       "\n",
       "   Mittlere_Absolute_Abweichung_z  Zentrales_Moment_x  Zentrales_Moment_y  \\\n",
       "0                         350.131                   0                   0   \n",
       "1                         363.095                   0                   0   \n",
       "2                         395.262                   0                   0   \n",
       "3                         389.710                   0                   0   \n",
       "4                         414.196                   0                   0   \n",
       "\n",
       "   Zentrales_Moment_z  Median_x  Median_y  Median_z   Timestamp  \\\n",
       "0                   0       512      -512     15872  1604490000   \n",
       "1                   0       512      -512     15872  1604490000   \n",
       "2                   0       512      -512     15872  1604490000   \n",
       "3                   0       512      -512     15872  1604490000   \n",
       "4                   0       512      -512     15872  1604490000   \n",
       "\n",
       "                  Date  year  \n",
       "0  2020-11-04 11:40:00  2020  \n",
       "1  2020-11-04 11:40:00  2020  \n",
       "2  2020-11-04 11:40:00  2020  \n",
       "3  2020-11-04 11:40:00  2020  \n",
       "4  2020-11-04 11:40:00  2020  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allnew['year'] = pd.to_datetime(allnew['Date']).dt.year.to_list()\n",
    "allnew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length=len(allnew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 7308\n",
      "2021 737573\n",
      "2022 701035\n"
     ]
    }
   ],
   "source": [
    "for x in np.unique(allnew.year):\n",
    "    length=len(allnew[allnew.year==x])\n",
    "    print(f'{x}',length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一份长度: 481972\n",
      "第二份长度: 481972\n",
      "第三份长度: 481972\n"
     ]
    }
   ],
   "source": [
    "# 计算每份的长度\n",
    "partition_length = total_length // 3\n",
    "\n",
    "# 分割 DataFrame\n",
    "part1 = allnew.iloc[:partition_length]\n",
    "part2 = allnew.iloc[partition_length:2*partition_length]\n",
    "part3 = allnew.iloc[2*partition_length:]\n",
    "\n",
    "# 打印每份的长度\n",
    "print(\"第一份长度:\", len(part1))\n",
    "print(\"第二份长度:\", len(part2))\n",
    "print(\"第三份长度:\", len(part3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Schadensklasse</th>\n",
       "      <th>Mittelwert_x</th>\n",
       "      <th>Mittelwert_y</th>\n",
       "      <th>Mittelwert_z</th>\n",
       "      <th>Variance_x</th>\n",
       "      <th>Variance_y</th>\n",
       "      <th>Variance_z</th>\n",
       "      <th>Effektivwert_x</th>\n",
       "      <th>Effektivwert_y</th>\n",
       "      <th>...</th>\n",
       "      <th>Mittlere_Absolute_Abweichung_z</th>\n",
       "      <th>Zentrales_Moment_x</th>\n",
       "      <th>Zentrales_Moment_y</th>\n",
       "      <th>Zentrales_Moment_z</th>\n",
       "      <th>Median_x</th>\n",
       "      <th>Median_y</th>\n",
       "      <th>Median_z</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>569.600</td>\n",
       "      <td>-547.072</td>\n",
       "      <td>15889.7</td>\n",
       "      <td>108005.0</td>\n",
       "      <td>26911.8</td>\n",
       "      <td>220962</td>\n",
       "      <td>657.526</td>\n",
       "      <td>571.115</td>\n",
       "      <td>...</td>\n",
       "      <td>350.131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>545.792</td>\n",
       "      <td>-545.280</td>\n",
       "      <td>15879.7</td>\n",
       "      <td>96078.5</td>\n",
       "      <td>29592.9</td>\n",
       "      <td>235057</td>\n",
       "      <td>627.592</td>\n",
       "      <td>571.746</td>\n",
       "      <td>...</td>\n",
       "      <td>363.095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>565.248</td>\n",
       "      <td>-544.512</td>\n",
       "      <td>15885.8</td>\n",
       "      <td>105404.0</td>\n",
       "      <td>24460.9</td>\n",
       "      <td>256573</td>\n",
       "      <td>651.770</td>\n",
       "      <td>566.507</td>\n",
       "      <td>...</td>\n",
       "      <td>395.262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>566.784</td>\n",
       "      <td>-541.440</td>\n",
       "      <td>15920.1</td>\n",
       "      <td>106026.0</td>\n",
       "      <td>30555.6</td>\n",
       "      <td>241982</td>\n",
       "      <td>653.578</td>\n",
       "      <td>568.931</td>\n",
       "      <td>...</td>\n",
       "      <td>389.710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>567.040</td>\n",
       "      <td>-563.456</td>\n",
       "      <td>15917.1</td>\n",
       "      <td>115510.0</td>\n",
       "      <td>26411.1</td>\n",
       "      <td>268509</td>\n",
       "      <td>661.006</td>\n",
       "      <td>586.402</td>\n",
       "      <td>...</td>\n",
       "      <td>414.196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>-512</td>\n",
       "      <td>15872</td>\n",
       "      <td>1604490000</td>\n",
       "      <td>2020-11-04 11:40:00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81967</th>\n",
       "      <td>481968</td>\n",
       "      <td>2</td>\n",
       "      <td>157.184</td>\n",
       "      <td>-353.536</td>\n",
       "      <td>15788.8</td>\n",
       "      <td>97025.0</td>\n",
       "      <td>23868.4</td>\n",
       "      <td>248851</td>\n",
       "      <td>348.762</td>\n",
       "      <td>385.788</td>\n",
       "      <td>...</td>\n",
       "      <td>402.598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>-256</td>\n",
       "      <td>15872</td>\n",
       "      <td>1622560000</td>\n",
       "      <td>2021-06-01 15:06:40</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81968</th>\n",
       "      <td>481969</td>\n",
       "      <td>2</td>\n",
       "      <td>165.888</td>\n",
       "      <td>-337.664</td>\n",
       "      <td>15792.1</td>\n",
       "      <td>107199.0</td>\n",
       "      <td>21073.8</td>\n",
       "      <td>229780</td>\n",
       "      <td>366.894</td>\n",
       "      <td>367.518</td>\n",
       "      <td>...</td>\n",
       "      <td>394.965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>-256</td>\n",
       "      <td>15872</td>\n",
       "      <td>1622560000</td>\n",
       "      <td>2021-06-01 15:06:40</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81969</th>\n",
       "      <td>481970</td>\n",
       "      <td>2</td>\n",
       "      <td>183.040</td>\n",
       "      <td>-352.768</td>\n",
       "      <td>15785.5</td>\n",
       "      <td>101799.0</td>\n",
       "      <td>22377.8</td>\n",
       "      <td>250057</td>\n",
       "      <td>367.697</td>\n",
       "      <td>383.146</td>\n",
       "      <td>...</td>\n",
       "      <td>407.804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>-256</td>\n",
       "      <td>15872</td>\n",
       "      <td>1622560000</td>\n",
       "      <td>2021-06-01 15:06:40</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81970</th>\n",
       "      <td>481971</td>\n",
       "      <td>2</td>\n",
       "      <td>176.896</td>\n",
       "      <td>-340.736</td>\n",
       "      <td>15761.7</td>\n",
       "      <td>103094.0</td>\n",
       "      <td>29090.3</td>\n",
       "      <td>259470</td>\n",
       "      <td>366.447</td>\n",
       "      <td>381.002</td>\n",
       "      <td>...</td>\n",
       "      <td>418.277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>-256</td>\n",
       "      <td>15872</td>\n",
       "      <td>1622560000</td>\n",
       "      <td>2021-06-01 15:06:40</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81971</th>\n",
       "      <td>481972</td>\n",
       "      <td>2</td>\n",
       "      <td>174.080</td>\n",
       "      <td>-336.896</td>\n",
       "      <td>15778.3</td>\n",
       "      <td>103362.0</td>\n",
       "      <td>24413.2</td>\n",
       "      <td>238793</td>\n",
       "      <td>365.462</td>\n",
       "      <td>371.332</td>\n",
       "      <td>...</td>\n",
       "      <td>395.866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>-256</td>\n",
       "      <td>15872</td>\n",
       "      <td>1622560000</td>\n",
       "      <td>2021-06-01 15:06:40</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481972 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Schadensklasse  Mittelwert_x  Mittelwert_y  Mittelwert_z  \\\n",
       "0           1               2       569.600      -547.072       15889.7   \n",
       "1           2               2       545.792      -545.280       15879.7   \n",
       "2           3               2       565.248      -544.512       15885.8   \n",
       "3           4               2       566.784      -541.440       15920.1   \n",
       "4           5               2       567.040      -563.456       15917.1   \n",
       "...       ...             ...           ...           ...           ...   \n",
       "81967  481968               2       157.184      -353.536       15788.8   \n",
       "81968  481969               2       165.888      -337.664       15792.1   \n",
       "81969  481970               2       183.040      -352.768       15785.5   \n",
       "81970  481971               2       176.896      -340.736       15761.7   \n",
       "81971  481972               2       174.080      -336.896       15778.3   \n",
       "\n",
       "       Variance_x  Variance_y  Variance_z  Effektivwert_x  Effektivwert_y  \\\n",
       "0        108005.0     26911.8      220962         657.526         571.115   \n",
       "1         96078.5     29592.9      235057         627.592         571.746   \n",
       "2        105404.0     24460.9      256573         651.770         566.507   \n",
       "3        106026.0     30555.6      241982         653.578         568.931   \n",
       "4        115510.0     26411.1      268509         661.006         586.402   \n",
       "...           ...         ...         ...             ...             ...   \n",
       "81967     97025.0     23868.4      248851         348.762         385.788   \n",
       "81968    107199.0     21073.8      229780         366.894         367.518   \n",
       "81969    101799.0     22377.8      250057         367.697         383.146   \n",
       "81970    103094.0     29090.3      259470         366.447         381.002   \n",
       "81971    103362.0     24413.2      238793         365.462         371.332   \n",
       "\n",
       "       ...  Mittlere_Absolute_Abweichung_z  Zentrales_Moment_x  \\\n",
       "0      ...                         350.131                   0   \n",
       "1      ...                         363.095                   0   \n",
       "2      ...                         395.262                   0   \n",
       "3      ...                         389.710                   0   \n",
       "4      ...                         414.196                   0   \n",
       "...    ...                             ...                 ...   \n",
       "81967  ...                         402.598                   0   \n",
       "81968  ...                         394.965                   0   \n",
       "81969  ...                         407.804                   0   \n",
       "81970  ...                         418.277                   0   \n",
       "81971  ...                         395.866                   0   \n",
       "\n",
       "       Zentrales_Moment_y  Zentrales_Moment_z  Median_x  Median_y  Median_z  \\\n",
       "0                       0                   0       512      -512     15872   \n",
       "1                       0                   0       512      -512     15872   \n",
       "2                       0                   0       512      -512     15872   \n",
       "3                       0                   0       512      -512     15872   \n",
       "4                       0                   0       512      -512     15872   \n",
       "...                   ...                 ...       ...       ...       ...   \n",
       "81967                   0                   0       256      -256     15872   \n",
       "81968                   0                   0       256      -256     15872   \n",
       "81969                   0                   0       256      -256     15872   \n",
       "81970                   0                   0       256      -256     15872   \n",
       "81971                   0                   0       256      -256     15872   \n",
       "\n",
       "        Timestamp                 Date  year  \n",
       "0      1604490000  2020-11-04 11:40:00  2020  \n",
       "1      1604490000  2020-11-04 11:40:00  2020  \n",
       "2      1604490000  2020-11-04 11:40:00  2020  \n",
       "3      1604490000  2020-11-04 11:40:00  2020  \n",
       "4      1604490000  2020-11-04 11:40:00  2020  \n",
       "...           ...                  ...   ...  \n",
       "81967  1622560000  2021-06-01 15:06:40  2021  \n",
       "81968  1622560000  2021-06-01 15:06:40  2021  \n",
       "81969  1622560000  2021-06-01 15:06:40  2021  \n",
       "81970  1622560000  2021-06-01 15:06:40  2021  \n",
       "81971  1622560000  2021-06-01 15:06:40  2021  \n",
       "\n",
       "[481972 rows x 32 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 生成示例数据\n",
    "def generate_data(n_samples, n_steps):\n",
    "    X = np.random.randn(n_samples, n_steps, 1)\n",
    "    y = np.sin(np.arange(n_steps) / 10.0) + np.random.randn(n_steps) * 0.1\n",
    "    return X, y\n",
    "\n",
    "# 创建LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 准备数据\n",
    "n_samples = 3000\n",
    "n_steps = 100\n",
    "X, y = generate_data(n_samples, n_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.tools import load_dataloader_and_scaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_path=r'D:\\studydata\\Masterarbeit\\dataloader'\n",
    "test_pickel_file=os.path.join(dataloader_path,'Dte_combined_dataloader_samples.pkl')\n",
    "train_pickel_file=os.path.join(dataloader_path,'Dtr_combined_dataloader_samples.pkl')\n",
    "valid_pickel_file=os.path.join(dataloader_path,'Val_combined_dataloader_samples.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, scaler = load_dataloader_and_scaler(train_pickel_file)\n",
    "test_loader, scaler = load_dataloader_and_scaler(test_pickel_file)\n",
    "vali_loader, scaler = load_dataloader_and_scaler(valid_pickel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 1, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 1 - Mean Squared Error: 0.08396207\n",
      "Training batch 1, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 2 - Mean Squared Error: 0.08444817\n",
      "Training batch 1, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 3 - Mean Squared Error: 0.087776914\n",
      "Training batch 1, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 4 - Mean Squared Error: 0.0958791\n",
      "Training batch 1, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 5 - Mean Squared Error: 0.0983284\n",
      "Training batch 2, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 1 - Mean Squared Error: 0.09650224\n",
      "Training batch 2, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 2 - Mean Squared Error: 0.096376434\n",
      "Training batch 2, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 3 - Mean Squared Error: 0.096288286\n",
      "Training batch 2, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 4 - Mean Squared Error: 0.10261537\n",
      "Training batch 2, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 5 - Mean Squared Error: 0.10320531\n",
      "Training batch 3, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 1 - Mean Squared Error: 0.11379895\n",
      "Training batch 3, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 2 - Mean Squared Error: 0.11339762\n",
      "Training batch 3, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 3 - Mean Squared Error: 0.112920664\n",
      "Training batch 3, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 4 - Mean Squared Error: 0.1124408\n",
      "Training batch 3, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 5 - Mean Squared Error: 0.110401414\n",
      "Training batch 4, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 1 - Mean Squared Error: 0.10704206\n",
      "Training batch 4, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 2 - Mean Squared Error: 0.10689628\n",
      "Training batch 4, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.1, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 3 - Mean Squared Error: 0.10706214\n",
      "Training batch 4, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 4 - Mean Squared Error: 0.10704181\n",
      "Training batch 4, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 5 - Mean Squared Error: 0.10665715\n",
      "Training batch 5, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 1 - Mean Squared Error: 0.10804634\n",
      "Training batch 5, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 2 - Mean Squared Error: 0.118810855\n",
      "Training batch 5, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 3 - Mean Squared Error: 0.12509184\n",
      "Training batch 5, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 4 - Mean Squared Error: 0.12523767\n",
      "Training batch 5, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 5 - Mean Squared Error: 0.1254633\n",
      "Training batch 6, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 1 - Mean Squared Error: 0.1247917\n",
      "Training batch 6, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 2 - Mean Squared Error: 0.12717594\n",
      "Training batch 6, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 3 - Mean Squared Error: 0.13576263\n",
      "Training batch 6, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 4 - Mean Squared Error: 0.13742854\n",
      "Training batch 6, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 5 - Mean Squared Error: 0.14639692\n",
      "Training batch 7, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 1 - Mean Squared Error: 0.14800006\n",
      "Training batch 7, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 2 - Mean Squared Error: 0.1473665\n",
      "Training batch 7, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 3 - Mean Squared Error: 0.14721975\n",
      "Training batch 7, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 4 - Mean Squared Error: 0.14689511\n",
      "Training batch 7, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 5 - Mean Squared Error: 0.1445503\n",
      "Training batch 8, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 1 - Mean Squared Error: 0.16675755\n",
      "Training batch 8, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 2 - Mean Squared Error: 0.16518822\n",
      "Training batch 8, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 3 - Mean Squared Error: 0.17584467\n",
      "Training batch 8, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 4 - Mean Squared Error: 0.17536795\n",
      "Training batch 8, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 5 - Mean Squared Error: 0.17476498\n",
      "Training batch 9, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 1 - Mean Squared Error: 0.15347588\n",
      "Training batch 9, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 2 - Mean Squared Error: 0.15317534\n",
      "Training batch 9, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 3 - Mean Squared Error: 0.15498868\n",
      "Training batch 9, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 4 - Mean Squared Error: 0.15433283\n",
      "Training batch 9, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 5 - Mean Squared Error: 0.15462007\n",
      "Training batch 10, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 1 - Mean Squared Error: 0.15569536\n",
      "Training batch 10, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 2 - Mean Squared Error: 0.15305068\n",
      "Training batch 10, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 3 - Mean Squared Error: 0.15211573\n",
      "Training batch 10, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 4 - Mean Squared Error: 0.15182987\n",
      "Training batch 10, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 5 - Mean Squared Error: 0.15568793\n",
      "Training results saved to training_results.csv\n",
      "Best params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "Best Mean Squared Error: 0.08396207\n",
      "Best model saved to best_xgboost_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# 示例DataLoader\n",
    "class ExampleDataLoader:\n",
    "    def __iter__(self):\n",
    "        for _ in range(10):  # 假设有10个batch\n",
    "            x_train = torch.rand((5, 20, 10))\n",
    "            x_test_ = torch.rand((5, 20, 10))\n",
    "            y_train = torch.rand((5, 20, 10))\n",
    "            y_test = torch.rand((5, 20, 10))\n",
    "            yield x_train, x_test_, y_train, y_test\n",
    "\n",
    "train_loader = ExampleDataLoader()\n",
    "\n",
    "# 参数搜索空间\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'eta': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 初始化模型\n",
    "model = None\n",
    "\n",
    "# 存储最佳参数和最小误差\n",
    "best_params = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "# 每个批次的迭代次数\n",
    "num_iterations_per_batch = 5\n",
    "\n",
    "# 用于保存结果的列表\n",
    "results = []\n",
    "\n",
    "# 分批训练模型，尝试不同参数组合\n",
    "for batch_idx, (x_train, x_test_, y_train, y_test) in enumerate(train_loader):\n",
    "    for iteration in range(num_iterations_per_batch):\n",
    "        # 从搜索空间中随机选择一组参数\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'max_depth': random.choice(param_grid['max_depth']),\n",
    "            'eta': random.choice(param_grid['eta']),\n",
    "            'subsample': random.choice(param_grid['subsample']),\n",
    "            'colsample_bytree': random.choice(param_grid['colsample_bytree'])\n",
    "        }\n",
    "\n",
    "        print(f\"Training batch {batch_idx + 1}, iteration {iteration + 1} with params: {params}\")\n",
    "\n",
    "        # reshape the batch data to (samples, features)\n",
    "        num_samples = x_train.shape[0]\n",
    "        X_train_batch = x_train.numpy().reshape(-1, x_train.shape[2])\n",
    "        y_train_batch = y_train.numpy().reshape(-1, y_train.shape[2])\n",
    "\n",
    "        print(f\"X_train_batch shape: {X_train_batch.shape}\")  # (5*20, 10)\n",
    "        print(f\"y_train_batch shape: {y_train_batch.shape}\")  # (5*20, 10)\n",
    "\n",
    "        # Train model on each sample separately\n",
    "        for i in range(num_samples):\n",
    "            X_train_sample = X_train_batch[i * 20: (i + 1) * 20, :]\n",
    "            y_train_sample = y_train_batch[i * 20: (i + 1) * 20, :]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train_sample, label=y_train_sample)\n",
    "\n",
    "            # 如果模型已经有训练过的部分，我们继续训练它\n",
    "            if model is None:\n",
    "                model = xgb.train(params, dtrain, num_boost_round=1)\n",
    "            else:\n",
    "                model = xgb.train(params, dtrain, num_boost_round=1, xgb_model=model)\n",
    "\n",
    "        # 准备验证数据\n",
    "        X_valid = x_test_.numpy().reshape(-1, x_test_.shape[2])\n",
    "        y_valid = y_test.numpy().reshape(-1, y_test.shape[2])\n",
    "\n",
    "        # 预测\n",
    "        dvalid = xgb.DMatrix(X_valid)\n",
    "        y_pred = model.predict(dvalid)\n",
    "\n",
    "        # 将 y_pred 的形状与 y_valid 调整一致\n",
    "        y_pred = y_pred.reshape(y_valid.shape)\n",
    "\n",
    "        # 评估模型\n",
    "        mse = mean_squared_error(y_valid, y_pred)\n",
    "        print(f\"Batch {batch_idx + 1}, Iteration {iteration + 1} - Mean Squared Error:\", mse)\n",
    "\n",
    "        # 保存最佳参数\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "        # 将结果保存到列表中\n",
    "        results.append({\n",
    "            'batch': batch_idx + 1,\n",
    "            'iteration': iteration + 1,\n",
    "            'params': params,\n",
    "            'mse': mse\n",
    "        })\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('training_results.csv', index=False)\n",
    "\n",
    "print(\"Training results saved to training_results.csv\")\n",
    "\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_mse)\n",
    "\n",
    "# 将最佳模型保存到pkl文件\n",
    "with open('best_xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"Best model saved to best_xgboost_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 1, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 1 - Mean Squared Error: 0.092602946\n",
      "Training batch 1, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 2 - Mean Squared Error: 0.092775956\n",
      "Training batch 1, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 3 - Mean Squared Error: 0.09292155\n",
      "Training batch 1, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 4 - Mean Squared Error: 0.09451803\n",
      "Training batch 1, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 1, Iteration 5 - Mean Squared Error: 0.09552576\n",
      "Training batch 2, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 1 - Mean Squared Error: 0.09005167\n",
      "Training batch 2, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 2 - Mean Squared Error: 0.09931474\n",
      "Training batch 2, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 3 - Mean Squared Error: 0.09957958\n",
      "Training batch 2, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 4 - Mean Squared Error: 0.10873135\n",
      "Training batch 2, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 2, Iteration 5 - Mean Squared Error: 0.111597635\n",
      "Training batch 3, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 1 - Mean Squared Error: 0.109324455\n",
      "Training batch 3, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 2 - Mean Squared Error: 0.11702917\n",
      "Training batch 3, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 3 - Mean Squared Error: 0.11841035\n",
      "Training batch 3, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 4 - Mean Squared Error: 0.11873702\n",
      "Training batch 3, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 3, Iteration 5 - Mean Squared Error: 0.118854046\n",
      "Training batch 4, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 1 - Mean Squared Error: 0.11853862\n",
      "Training batch 4, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 2 - Mean Squared Error: 0.11775692\n",
      "Training batch 4, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 3 - Mean Squared Error: 0.11969334\n",
      "Training batch 4, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 4 - Mean Squared Error: 0.12690848\n",
      "Training batch 4, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 4, Iteration 5 - Mean Squared Error: 0.12704402\n",
      "Training batch 5, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 1 - Mean Squared Error: 0.13737316\n",
      "Training batch 5, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 2 - Mean Squared Error: 0.13655385\n",
      "Training batch 5, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 3 - Mean Squared Error: 0.14462134\n",
      "Training batch 5, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 4 - Mean Squared Error: 0.15586905\n",
      "Training batch 5, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 5, Iteration 5 - Mean Squared Error: 0.16039295\n",
      "Training batch 6, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 1 - Mean Squared Error: 0.15464531\n",
      "Training batch 6, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 2 - Mean Squared Error: 0.15463091\n",
      "Training batch 6, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 3 - Mean Squared Error: 0.16690317\n",
      "Training batch 6, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 4 - Mean Squared Error: 0.17023417\n",
      "Training batch 6, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 6, Iteration 5 - Mean Squared Error: 0.170427\n",
      "Training batch 7, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 1 - Mean Squared Error: 0.17201538\n",
      "Training batch 7, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 2 - Mean Squared Error: 0.1702921\n",
      "Training batch 7, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 3 - Mean Squared Error: 0.16720435\n",
      "Training batch 7, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 4 - Mean Squared Error: 0.1828345\n",
      "Training batch 7, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 7, Iteration 5 - Mean Squared Error: 0.18470901\n",
      "Training batch 8, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 1 - Mean Squared Error: 0.17124687\n",
      "Training batch 8, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 2 - Mean Squared Error: 0.17413355\n",
      "Training batch 8, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 3 - Mean Squared Error: 0.17408963\n",
      "Training batch 8, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 4 - Mean Squared Error: 0.17270076\n",
      "Training batch 8, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.05, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 8, Iteration 5 - Mean Squared Error: 0.1732547\n",
      "Training batch 9, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 1 - Mean Squared Error: 0.16911253\n",
      "Training batch 9, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 2 - Mean Squared Error: 0.1675081\n",
      "Training batch 9, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 5, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 3 - Mean Squared Error: 0.16701134\n",
      "Training batch 9, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.05, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 4 - Mean Squared Error: 0.16693857\n",
      "Training batch 9, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.2, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 9, Iteration 5 - Mean Squared Error: 0.17150596\n",
      "Training batch 10, iteration 1 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 1 - Mean Squared Error: 0.18046275\n",
      "Training batch 10, iteration 2 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 10, 'eta': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.8}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 2 - Mean Squared Error: 0.18051913\n",
      "Training batch 10, iteration 3 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.1, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 3 - Mean Squared Error: 0.17915459\n",
      "Training batch 10, iteration 4 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 3, 'eta': 0.05, 'subsample': 0.6, 'colsample_bytree': 1.0}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 4 - Mean Squared Error: 0.1781812\n",
      "Training batch 10, iteration 5 with params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.6}\n",
      "X_train_batch shape: (100, 10)\n",
      "y_train_batch shape: (100, 10)\n",
      "Batch 10, Iteration 5 - Mean Squared Error: 0.17743158\n",
      "Training results saved to training_results.csv\n",
      "Best params: {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 7, 'eta': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best Mean Squared Error: 0.09005167\n",
      "Best model saved to best_xgboost_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# 示例DataLoader\n",
    "class ExampleDataLoader:\n",
    "    def __iter__(self):\n",
    "        for _ in range(10):  # 假设有10个batch\n",
    "            x_train = torch.rand((5, 20, 10))\n",
    "            x_test_ = torch.rand((5, 20, 10))\n",
    "            y_train = torch.rand((5, 20, 10))\n",
    "            y_test = torch.rand((5, 20, 10))\n",
    "            yield x_train, x_test_, y_train, y_test\n",
    "\n",
    "train_loader = ExampleDataLoader()\n",
    "\n",
    "# 参数搜索空间\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'eta': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 初始化模型\n",
    "model = None\n",
    "\n",
    "# 存储最佳参数和最小误差\n",
    "best_params = None\n",
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "\n",
    "# 每个批次的迭代次数\n",
    "num_iterations_per_batch = 5\n",
    "\n",
    "# 用于保存结果的列表\n",
    "results = []\n",
    "\n",
    "# 分批训练模型，尝试不同参数组合\n",
    "for batch_idx, (x_train, x_test_, y_train, y_test) in enumerate(train_loader):\n",
    "    for iteration in range(num_iterations_per_batch):\n",
    "        # 从搜索空间中随机选择一组参数\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'max_depth': random.choice(param_grid['max_depth']),\n",
    "            'eta': random.choice(param_grid['eta']),\n",
    "            'subsample': random.choice(param_grid['subsample']),\n",
    "            'colsample_bytree': random.choice(param_grid['colsample_bytree'])\n",
    "        }\n",
    "\n",
    "        print(f\"Training batch {batch_idx + 1}, iteration {iteration + 1} with params: {params}\")\n",
    "\n",
    "        # reshape the batch data to (samples, features)\n",
    "        num_samples = x_train.shape[0]\n",
    "        X_train_batch = x_train.numpy().reshape(-1, x_train.shape[2])\n",
    "        y_train_batch = y_train.numpy().reshape(-1, y_train.shape[2])\n",
    "\n",
    "        print(f\"X_train_batch shape: {X_train_batch.shape}\")  # (5*20, 10)\n",
    "        print(f\"y_train_batch shape: {y_train_batch.shape}\")  # (5*20, 10)\n",
    "\n",
    "        # Train model on each sample separately\n",
    "        for i in range(num_samples):\n",
    "            X_train_sample = X_train_batch[i * 20: (i + 1) * 20, :]\n",
    "            y_train_sample = y_train_batch[i * 20: (i + 1) * 20, :]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train_sample, label=y_train_sample)\n",
    "\n",
    "            # 如果模型已经有训练过的部分，我们继续训练它\n",
    "            if model is None:\n",
    "                model = xgb.train(params, dtrain, num_boost_round=1)\n",
    "            else:\n",
    "                model = xgb.train(params, dtrain, num_boost_round=1, xgb_model=model)\n",
    "\n",
    "        # 准备验证数据\n",
    "        X_valid = x_test_.numpy().reshape(-1, x_test_.shape[2])\n",
    "        y_valid = y_test.numpy().reshape(-1, y_test.shape[2])\n",
    "\n",
    "        # 预测\n",
    "        dvalid = xgb.DMatrix(X_valid)\n",
    "        y_pred = model.predict(dvalid)\n",
    "\n",
    "        # 将 y_pred 的形状与 y_valid 调整一致\n",
    "        y_pred = y_pred.reshape(y_valid.shape)\n",
    "\n",
    "        # 评估模型\n",
    "        mse = mean_squared_error(y_valid, y_pred)\n",
    "        print(f\"Batch {batch_idx + 1}, Iteration {iteration + 1} - Mean Squared Error:\", mse)\n",
    "\n",
    "        # 保存最佳参数和模型\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "            # 将结果保存到列表中\n",
    "            results.append({\n",
    "                'batch': batch_idx + 1,\n",
    "                'iteration': iteration + 1,\n",
    "                'params': params,\n",
    "                'mse': mse\n",
    "            })\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('training_results_better.csv', index=False)\n",
    "\n",
    "print(\"Training results saved to training_results.csv\")\n",
    "\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best Mean Squared Error:\", best_mse)\n",
    "\n",
    "# 将最佳模型保存到pkl文件\n",
    "with open('best_xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"Best model saved to best_xgboost_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Autoformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
